# ExercÃ­cio 03 - Avaliador de CritÃ©rios Simples ğŸ”µ

**NÃ­vel:** BÃ¡sico  
**Tempo Estimado:** 35-45 minutos  
**Objetivo:** Implementar sistema bÃ¡sico de avaliaÃ§Ã£o de critÃ©rios de parada

## Contexto

Como engenheiro de qualidade em uma consultoria de software, vocÃª precisa criar uma ferramenta que automatize a avaliaÃ§Ã£o de critÃ©rios de parada para diferentes clientes. Cada cliente tem critÃ©rios especÃ­ficos, e vocÃª precisa de um sistema flexÃ­vel que avalie automaticamente se um projeto estÃ¡ pronto para release.

A ferramenta deve ser simples mas robusta, permitindo configurar diferentes tipos de critÃ©rios (obrigatÃ³rios, condicionais, de escape) e fornecer decisÃµes claras com justificativas detalhadas.

## CenÃ¡rio de Uso

VocÃª tem trÃªs clientes com perfis diferentes:

### Cliente A - Fintech (Rigoroso)
```python
criteria_fintech = {
    "mandatory": {
        "coverage_critical": {"target": 98.0, "operator": ">="},
        "coverage_general": {"target": 90.0, "operator": ">="},
        "critical_defects": {"target": 0, "operator": "=="},
        "security_vulnerabilities": {"target": 0, "operator": "=="}
    },
    "conditional": {
        "dre": {"target": 95.0, "operator": ">="},
        "performance_degradation": {"target": 5.0, "operator": "<="},
        "code_review_coverage": {"target": 100.0, "operator": "=="}
    },
    "escape": {
        "data_corruption_risk": {"target": True, "operator": "=="},
        "regulatory_compliance": {"target": False, "operator": "=="}
    },
    "conditional_threshold": 2  # Pelo menos 2 de 3 condicionais
}
```

### Cliente B - Startup (Balanceado)
```python
criteria_startup = {
    "mandatory": {
        "coverage_general": {"target": 75.0, "operator": ">="},
        "critical_defects": {"target": 0, "operator": "=="},
        "smoke_tests": {"target": True, "operator": "=="}
    },
    "conditional": {
        "dre": {"target": 85.0, "operator": ">="},
        "user_acceptance": {"target": 80.0, "operator": ">="},
        "performance_acceptable": {"target": True, "operator": "=="}
    },
    "escape": {
        "budget_exceeded": {"target": True, "operator": "=="},
        "deadline_critical": {"target": True, "operator": "=="}
    },
    "conditional_threshold": 2  # Pelo menos 2 de 3 condicionais
}
```

### Cliente C - Prototipo (FlexÃ­vel)
```python
criteria_prototype = {
    "mandatory": {
        "basic_functionality": {"target": True, "operator": "=="},
        "core_features": {"target": 100.0, "operator": "=="}
    },
    "conditional": {
        "coverage_general": {"target": 60.0, "operator": ">="},
        "user_feedback": {"target": 70.0, "operator": ">="}
    },
    "escape": {
        "demo_deadline": {"target": True, "operator": "=="}
    },
    "conditional_threshold": 1  # Pelo menos 1 de 2 condicionais
}
```

## Dados de Teste

```python
# Dados do projeto Fintech atual
fintech_metrics = {
    "coverage_critical": 97.5,
    "coverage_general": 91.2,
    "critical_defects": 0,
    "security_vulnerabilities": 1,  # Problema!
    "dre": 96.8,
    "performance_degradation": 3.2,
    "code_review_coverage": 100.0,
    "data_corruption_risk": False,
    "regulatory_compliance": False
}

# Dados do projeto Startup atual  
startup_metrics = {
    "coverage_general": 78.5,
    "critical_defects": 0,
    "smoke_tests": True,
    "dre": 87.3,
    "user_acceptance": 82.1,
    "performance_acceptable": True,
    "budget_exceeded": False,
    "deadline_critical": False
}

# Dados do projeto Prototipo atual
prototype_metrics = {
    "basic_functionality": True,
    "core_features": 100.0,
    "coverage_general": 55.8,  # Abaixo do critÃ©rio
    "user_feedback": 75.2,
    "demo_deadline": False
}
```

## Requisitos Funcionais

### RF01 - AvaliaÃ§Ã£o de CritÃ©rio Individual
Implementar funÃ§Ã£o que avalia se uma mÃ©trica individual atende seu critÃ©rio:
- Suporte a operadores: `>=`, `<=`, `==`, `!=`, `>`, `<`
- Tratamento de tipos: `int`, `float`, `bool`
- Retorno estruturado com detalhes da avaliaÃ§Ã£o

### RF02 - AvaliaÃ§Ã£o de CritÃ©rios por Tipo
Avaliar separadamente:
- **ObrigatÃ³rios:** Todos devem ser satisfeitos
- **Condicionais:** Pelo menos N de M devem ser satisfeitos  
- **Escape:** Qualquer um forÃ§a parada imediata

### RF03 - DecisÃ£o Final de Parada
Combinar avaliaÃ§Ãµes para decidir:
- **PARAR:** Todos obrigatÃ³rios + condicionais suficientes + sem escape negativo
- **CONTINUAR:** Qualquer falha nos critÃ©rios acima

### RF04 - RelatÃ³rio Detalhado
Gerar relatÃ³rio explicando:
- Status de cada critÃ©rio individual
- RazÃ£o da decisÃ£o final
- RecomendaÃ§Ãµes para critÃ©rios nÃ£o atendidos

## Estrutura de CÃ³digo Base

```python
"""
criteria_evaluator.py

Sistema de avaliaÃ§Ã£o de critÃ©rios de parada flexÃ­vel e configurÃ¡vel.
Suporta diferentes tipos de critÃ©rios e operadores lÃ³gicos.
"""

from typing import Dict, List, Any, Union
from dataclasses import dataclass
from enum import Enum

class CriteriaType(Enum):
    """Tipos de critÃ©rios suportados."""
    MANDATORY = "mandatory"
    CONDITIONAL = "conditional"  
    ESCAPE = "escape"

class DecisionType(Enum):
    """Tipos de decisÃ£o de parada."""
    STOP = "PARAR"
    CONTINUE = "CONTINUAR"

@dataclass
class CriterionResult:
    """Resultado da avaliaÃ§Ã£o de um critÃ©rio individual."""
    name: str
    type: CriteriaType
    current_value: Any
    target_value: Any
    operator: str
    satisfied: bool
    description: str

@dataclass
class EvaluationSummary:
    """Resumo da avaliaÃ§Ã£o de critÃ©rios."""
    decision: DecisionType
    mandatory_passed: int
    mandatory_total: int
    conditional_passed: int
    conditional_total: int
    conditional_required: int
    escape_triggered: bool
    detailed_results: List[CriterionResult]
    justification: str
    recommendations: List[str]

class SimpleCriteriaEvaluator:
    """
    Avaliador simples de critÃ©rios de parada.
    
    Implementa lÃ³gica bÃ¡sica para combinar diferentes tipos
    de critÃ©rios e tomar decisÃµes automatizadas.
    """
    
    def __init__(self):
        """Inicializa avaliador com operadores suportados."""
        self.supported_operators = {
            ">=": lambda current, target: current >= target,
            "<=": lambda current, target: current <= target,
            "==": lambda current, target: current == target,
            "!=": lambda current, target: current != target,
            ">": lambda current, target: current > target,
            "<": lambda current, target: current < target
        }
    
    def evaluate_single_criterion(self, name: str, 
                                 current_value: Any,
                                 criterion_config: Dict[str, Any],
                                 criterion_type: CriteriaType) -> CriterionResult:
        """
        Avalia um critÃ©rio individual.
        
        Args:
            name: Nome do critÃ©rio
            current_value: Valor atual da mÃ©trica
            criterion_config: ConfiguraÃ§Ã£o do critÃ©rio (target, operator)
            criterion_type: Tipo do critÃ©rio
            
        Returns:
            CriterionResult com resultado da avaliaÃ§Ã£o
        """
        # TODO: Implementar avaliaÃ§Ã£o individual
        pass
    
    def evaluate_criteria_group(self, metrics: Dict[str, Any],
                               criteria_config: Dict[str, Dict],
                               criterion_type: CriteriaType) -> List[CriterionResult]:
        """
        Avalia um grupo de critÃ©rios do mesmo tipo.
        
        Args:
            metrics: MÃ©tricas atuais do projeto
            criteria_config: ConfiguraÃ§Ã£o dos critÃ©rios
            criterion_type: Tipo dos critÃ©rios
            
        Returns:
            Lista de CriterionResult
        """
        # TODO: Implementar avaliaÃ§Ã£o de grupo
        pass
    
    def evaluate_all_criteria(self, metrics: Dict[str, Any],
                            criteria_config: Dict) -> EvaluationSummary:
        """
        Avalia todos os critÃ©rios e toma decisÃ£o final.
        
        Args:
            metrics: MÃ©tricas atuais do projeto
            criteria_config: ConfiguraÃ§Ã£o completa dos critÃ©rios
            
        Returns:
            EvaluationSummary com decisÃ£o e detalhes
        """
        # TODO: Implementar avaliaÃ§Ã£o completa
        pass
    
    def _determine_final_decision(self, mandatory_results: List[CriterionResult],
                                conditional_results: List[CriterionResult],
                                escape_results: List[CriterionResult],
                                conditional_threshold: int) -> DecisionType:
        """
        Determina decisÃ£o final baseada em todas as avaliaÃ§Ãµes.
        
        Args:
            mandatory_results: Resultados dos critÃ©rios obrigatÃ³rios
            conditional_results: Resultados dos critÃ©rios condicionais
            escape_results: Resultados dos critÃ©rios de escape
            conditional_threshold: MÃ­nimo de condicionais necessÃ¡rios
            
        Returns:
            DecisionType apropriada
        """
        # TODO: Implementar lÃ³gica de decisÃ£o
        pass
    
    def _generate_justification(self, summary: EvaluationSummary) -> str:
        """
        Gera justificativa textual para a decisÃ£o.
        
        Args:
            summary: Resumo da avaliaÃ§Ã£o
            
        Returns:
            Justificativa em linguagem natural
        """
        # TODO: Implementar geraÃ§Ã£o de justificativa
        pass
    
    def _generate_recommendations(self, failed_criteria: List[CriterionResult]) -> List[str]:
        """
        Gera recomendaÃ§Ãµes para critÃ©rios nÃ£o atendidos.
        
        Args:
            failed_criteria: Lista de critÃ©rios que falharam
            
        Returns:
            Lista de recomendaÃ§Ãµes especÃ­ficas
        """
        # TODO: Implementar geraÃ§Ã£o de recomendaÃ§Ãµes
        pass
    
    def generate_detailed_report(self, summary: EvaluationSummary,
                               project_name: str) -> str:
        """
        Gera relatÃ³rio detalhado da avaliaÃ§Ã£o.
        
        Args:
            summary: Resumo da avaliaÃ§Ã£o
            project_name: Nome do projeto avaliado
            
        Returns:
            RelatÃ³rio formatado em texto
        """
        # TODO: Implementar geraÃ§Ã£o de relatÃ³rio
        pass

def main():
    """FunÃ§Ã£o principal para testar os trÃªs cenÃ¡rios."""
    evaluator = SimpleCriteriaEvaluator()
    
    test_cases = [
        ("Fintech", fintech_metrics, criteria_fintech),
        ("Startup", startup_metrics, criteria_startup),
        ("Prototipo", prototype_metrics, criteria_prototype)
    ]
    
    print("=== AVALIADOR DE CRITÃ‰RIOS DE PARADA ===")
    print()
    
    for project_name, metrics, criteria in test_cases:
        print(f"ğŸ” Avaliando projeto: {project_name}")
        
        # TODO: Avaliar critÃ©rios e exibir resultado
        # summary = evaluator.evaluate_all_criteria(metrics, criteria)
        # report = evaluator.generate_detailed_report(summary, project_name)
        # print(report)
        print("-" * 60)

if __name__ == "__main__":
    main()
```

## Tarefas EspecÃ­ficas

### Tarefa 1: ImplementaÃ§Ã£o dos Operadores
Implemente suporte robusto para todos os operadores lÃ³gicos com tratamento de tipos.

### Tarefa 2: LÃ³gica de CombinaÃ§Ã£o
Implemente a lÃ³gica para combinar critÃ©rios obrigatÃ³rios, condicionais e de escape.

### Tarefa 3: Tratamento de Erros
Adicione validaÃ§Ã£o para:
- MÃ©tricas ausentes
- Operadores invÃ¡lidos  
- Tipos incompatÃ­veis
- ConfiguraÃ§Ãµes malformadas

### Tarefa 4: GeraÃ§Ã£o de RelatÃ³rios
Crie relatÃ³rios informativos e acionÃ¡veis que expliquem claramente as decisÃµes.

## Resultados Esperados

### Projeto Fintech
- **DecisÃ£o:** CONTINUAR
- **Motivo:** 1 vulnerabilidade de seguranÃ§a (critÃ©rio obrigatÃ³rio falhou)
- **RecomendaÃ§Ã£o:** Corrigir vulnerabilidade antes de continuar

### Projeto Startup
- **DecisÃ£o:** PARAR
- **Motivo:** Todos os critÃ©rios atendidos
- **ObservaÃ§Ã£o:** Projeto pronto para release

### Projeto Prototipo  
- **DecisÃ£o:** PARAR
- **Motivo:** CritÃ©rio de escape ativado (demo_deadline)
- **ObservaÃ§Ã£o:** Deadline forÃ§a release mesmo com cobertura baixa

## Casos de Teste

```python
# Teste 1: CritÃ©rio simples com nÃºmeros
assert evaluator.evaluate_single_criterion(
    "coverage", 85.5, {"target": 80.0, "operator": ">="}, 
    CriteriaType.MANDATORY
).satisfied == True

# Teste 2: CritÃ©rio com booleanos
assert evaluator.evaluate_single_criterion(
    "tests_pass", True, {"target": True, "operator": "=="}, 
    CriteriaType.MANDATORY
).satisfied == True

# Teste 3: Operador incorreto
# Deve levantar ValueError

# Teste 4: MÃ©trica ausente  
# Deve ser tratado graciosamente
```

## CritÃ©rios de AvaliaÃ§Ã£o

| Aspecto | Excelente (4) | Bom (3) | SatisfatÃ³rio (2) | Insuficiente (1) |
|---------|---------------|---------|------------------|------------------|
| **LÃ³gica de AvaliaÃ§Ã£o** | Todos os tipos de critÃ©rios implementados corretamente | ImplementaÃ§Ã£o sÃ³lida com pequenos gaps | LÃ³gica bÃ¡sica funcional | LÃ³gica incompleta ou incorreta |
| **Tratamento de Tipos** | Suporte robusto para int, float, bool | Suporte adequado com validaÃ§Ã£o | Suporte bÃ¡sico funcional | Problemas com tipos diferentes |
| **RelatÃ³rios e Mensagens** | RelatÃ³rios claros e acionÃ¡veis | RelatÃ³rios informativos | RelatÃ³rios bÃ¡sicos mas Ãºteis | RelatÃ³rios confusos ou inÃºteis |
| **Robustez** | Tratamento excelente de casos extremos | Boa validaÃ§Ã£o e tratamento de erros | ValidaÃ§Ã£o bÃ¡sica adequada | Pouco ou nenhum tratamento de erros |

## Dicas de ImplementaÃ§Ã£o

ğŸ’¡ **ValidaÃ§Ã£o primeiro:** Implemente validaÃ§Ã£o robusta antes da lÃ³gica principal  

ğŸ’¡ **Estruture a decisÃ£o:** Use enum para decisÃµes e tipos para clareza  

ğŸ’¡ **Mensagens contextuais:** Personalize mensagens baseado no tipo de critÃ©rio  

ğŸ’¡ **Teste incremental:** Teste cada tipo de critÃ©rio separadamente primeiro  

ğŸ’¡ **Logs de debug:** Adicione prints para acompanhar o fluxo de decisÃ£o  

## EntregÃ¡veis

1. **`criteria_evaluator.py`** - ImplementaÃ§Ã£o completa do avaliador
2. **`test_scenarios.py`** - Script demonstrando os trÃªs cenÃ¡rios
3. **`evaluation_reports.txt`** - RelatÃ³rios dos trÃªs projetos
4. **`reflexao.md`** - ReflexÃ£o sobre:
   - Desafios de automatizar decisÃµes subjetivas
   - ImportÃ¢ncia de configurabilidade vs. simplicidade
   - LiÃ§Ãµes sobre comunicaÃ§Ã£o de decisÃµes automatizadas

## ExtensÃµes Opcionais (BÃ´nus)

ğŸ¯ **CritÃ©rios com peso:** Implemente pesos diferentes para critÃ©rios  
ğŸ¯ **HistÃ³rico de decisÃµes:** Salve e compare decisÃµes ao longo do tempo  
ğŸ¯ **SimulaÃ§Ã£o de cenÃ¡rios:** Permita testar "e se" com mÃ©tricas modificadas  
ğŸ¯ **Export para JSON:** Salve configuraÃ§Ãµes e resultados estruturados  

---

**Foque na clareza da lÃ³gica e utilidade dos relatÃ³rios!** âš–ï¸
