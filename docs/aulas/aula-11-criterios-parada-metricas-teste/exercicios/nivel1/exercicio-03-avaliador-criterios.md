# Exerc√≠cio 03 - Avaliador de Crit√©rios Simples üîµ

**N√≠vel:** B√°sico  
**Tempo Estimado:** 35-45 minutos  
**Objetivo:** Implementar sistema b√°sico de avalia√ß√£o de crit√©rios de parada

## Contexto

Como engenheiro de qualidade em uma consultoria de software, voc√™ precisa criar uma ferramenta que automatize a avalia√ß√£o de crit√©rios de parada para diferentes clientes. Cada cliente tem crit√©rios espec√≠ficos, e voc√™ precisa de um sistema flex√≠vel que avalie automaticamente se um projeto est√° pronto para release.

A ferramenta deve ser simples mas robusta, permitindo configurar diferentes tipos de crit√©rios (obrigat√≥rios, condicionais, de escape) e fornecer decis√µes claras com justificativas detalhadas.

## Cen√°rio de Uso

Voc√™ tem tr√™s clientes com perfis diferentes:

### Cliente A - Fintech (Rigoroso)
```python
criteria_fintech = {
    "mandatory": {
        "coverage_critical": {"target": 98.0, "operator": ">="},
        "coverage_general": {"target": 90.0, "operator": ">="},
        "critical_defects": {"target": 0, "operator": "=="},
        "security_vulnerabilities": {"target": 0, "operator": "=="}
    },
    "conditional": {
        "dre": {"target": 95.0, "operator": ">="},
        "performance_degradation": {"target": 5.0, "operator": "<="},
        "code_review_coverage": {"target": 100.0, "operator": "=="}
    },
    "escape": {
        "data_corruption_risk": {"target": True, "operator": "=="},
        "regulatory_compliance": {"target": False, "operator": "=="}
    },
    "conditional_threshold": 2  # Pelo menos 2 de 3 condicionais
}
```

### Cliente B - Startup (Balanceado)
```python
criteria_startup = {
    "mandatory": {
        "coverage_general": {"target": 75.0, "operator": ">="},
        "critical_defects": {"target": 0, "operator": "=="},
        "smoke_tests": {"target": True, "operator": "=="}
    },
    "conditional": {
        "dre": {"target": 85.0, "operator": ">="},
        "user_acceptance": {"target": 80.0, "operator": ">="},
        "performance_acceptable": {"target": True, "operator": "=="}
    },
    "escape": {
        "budget_exceeded": {"target": True, "operator": "=="},
        "deadline_critical": {"target": True, "operator": "=="}
    },
    "conditional_threshold": 2  # Pelo menos 2 de 3 condicionais
}
```

### Cliente C - Prototipo (Flex√≠vel)
```python
criteria_prototype = {
    "mandatory": {
        "basic_functionality": {"target": True, "operator": "=="},
        "core_features": {"target": 100.0, "operator": "=="}
    },
    "conditional": {
        "coverage_general": {"target": 60.0, "operator": ">="},
        "user_feedback": {"target": 70.0, "operator": ">="}
    },
    "escape": {
        "demo_deadline": {"target": True, "operator": "=="}
    },
    "conditional_threshold": 1  # Pelo menos 1 de 2 condicionais
}
```

## Dados de Teste

```python
# Dados do projeto Fintech atual
fintech_metrics = {
    "coverage_critical": 97.5,
    "coverage_general": 91.2,
    "critical_defects": 0,
    "security_vulnerabilities": 1,  # Problema!
    "dre": 96.8,
    "performance_degradation": 3.2,
    "code_review_coverage": 100.0,
    "data_corruption_risk": False,
    "regulatory_compliance": False
}

# Dados do projeto Startup atual  
startup_metrics = {
    "coverage_general": 78.5,
    "critical_defects": 0,
    "smoke_tests": True,
    "dre": 87.3,
    "user_acceptance": 82.1,
    "performance_acceptable": True,
    "budget_exceeded": False,
    "deadline_critical": False
}

# Dados do projeto Prototipo atual
prototype_metrics = {
    "basic_functionality": True,
    "core_features": 100.0,
    "coverage_general": 55.8,  # Abaixo do crit√©rio
    "user_feedback": 75.2,
    "demo_deadline": False
}
```

## Requisitos Funcionais

### RF01 - Avalia√ß√£o de Crit√©rio Individual
Implementar fun√ß√£o que avalia se uma m√©trica individual atende seu crit√©rio:
- Suporte a operadores: `>=`, `<=`, `==`, `!=`, `>`, `<`
- Tratamento de tipos: `int`, `float`, `bool`
- Retorno estruturado com detalhes da avalia√ß√£o

### RF02 - Avalia√ß√£o de Crit√©rios por Tipo
Avaliar separadamente:
- **Obrigat√≥rios:** Todos devem ser satisfeitos
- **Condicionais:** Pelo menos N de M devem ser satisfeitos  
- **Escape:** Qualquer um for√ßa parada imediata

### RF03 - Decis√£o Final de Parada
Combinar avalia√ß√µes para decidir:
- **PARAR:** Todos obrigat√≥rios + condicionais suficientes + sem escape negativo
- **CONTINUAR:** Qualquer falha nos crit√©rios acima

### RF04 - Relat√≥rio Detalhado
Gerar relat√≥rio explicando:
- Status de cada crit√©rio individual
- Raz√£o da decis√£o final
- Recomenda√ß√µes para crit√©rios n√£o atendidos

## Estrutura de C√≥digo Base

```python
"""
criteria_evaluator.py

Sistema de avalia√ß√£o de crit√©rios de parada flex√≠vel e configur√°vel.
Suporta diferentes tipos de crit√©rios e operadores l√≥gicos.
"""

from typing import Dict, List, Any, Union
from dataclasses import dataclass
from enum import Enum

class CriteriaType(Enum):
    """Tipos de crit√©rios suportados."""
    MANDATORY = "mandatory"
    CONDITIONAL = "conditional"  
    ESCAPE = "escape"

class DecisionType(Enum):
    """Tipos de decis√£o de parada."""
    STOP = "PARAR"
    CONTINUE = "CONTINUAR"

@dataclass
class CriterionResult:
    """Resultado da avalia√ß√£o de um crit√©rio individual."""
    name: str
    type: CriteriaType
    current_value: Any
    target_value: Any
    operator: str
    satisfied: bool
    description: str

@dataclass
class EvaluationSummary:
    """Resumo da avalia√ß√£o de crit√©rios."""
    decision: DecisionType
    mandatory_passed: int
    mandatory_total: int
    conditional_passed: int
    conditional_total: int
    conditional_required: int
    escape_triggered: bool
    detailed_results: List[CriterionResult]
    justification: str
    recommendations: List[str]

class SimpleCriteriaEvaluator:
    """
    Avaliador simples de crit√©rios de parada.
    
    Implementa l√≥gica b√°sica para combinar diferentes tipos
    de crit√©rios e tomar decis√µes automatizadas.
    """
    
    def __init__(self):
        """Inicializa avaliador com operadores suportados."""
        self.supported_operators = {
            ">=": lambda current, target: current >= target,
            "<=": lambda current, target: current <= target,
            "==": lambda current, target: current == target,
            "!=": lambda current, target: current != target,
            ">": lambda current, target: current > target,
            "<": lambda current, target: current < target
        }
    
    def evaluate_single_criterion(self, name: str, 
                                 current_value: Any,
                                 criterion_config: Dict[str, Any],
                                 criterion_type: CriteriaType) -> CriterionResult:
        """
        Avalia um crit√©rio individual.
        
        Args:
            name: Nome do crit√©rio
            current_value: Valor atual da m√©trica
            criterion_config: Configura√ß√£o do crit√©rio (target, operator)
            criterion_type: Tipo do crit√©rio
            
        Returns:
            CriterionResult com resultado da avalia√ß√£o
        """
        # TODO: Implementar avalia√ß√£o individual
        pass
    
    def evaluate_criteria_group(self, metrics: Dict[str, Any],
                               criteria_config: Dict[str, Dict],
                               criterion_type: CriteriaType) -> List[CriterionResult]:
        """
        Avalia um grupo de crit√©rios do mesmo tipo.
        
        Args:
            metrics: M√©tricas atuais do projeto
            criteria_config: Configura√ß√£o dos crit√©rios
            criterion_type: Tipo dos crit√©rios
            
        Returns:
            Lista de CriterionResult
        """
        # TODO: Implementar avalia√ß√£o de grupo
        pass
    
    def evaluate_all_criteria(self, metrics: Dict[str, Any],
                            criteria_config: Dict) -> EvaluationSummary:
        """
        Avalia todos os crit√©rios e toma decis√£o final.
        
        Args:
            metrics: M√©tricas atuais do projeto
            criteria_config: Configura√ß√£o completa dos crit√©rios
            
        Returns:
            EvaluationSummary com decis√£o e detalhes
        """
        # TODO: Implementar avalia√ß√£o completa
        pass
    
    def _determine_final_decision(self, mandatory_results: List[CriterionResult],
                                conditional_results: List[CriterionResult],
                                escape_results: List[CriterionResult],
                                conditional_threshold: int) -> DecisionType:
        """
        Determina decis√£o final baseada em todas as avalia√ß√µes.
        
        Args:
            mandatory_results: Resultados dos crit√©rios obrigat√≥rios
            conditional_results: Resultados dos crit√©rios condicionais
            escape_results: Resultados dos crit√©rios de escape
            conditional_threshold: M√≠nimo de condicionais necess√°rios
            
        Returns:
            DecisionType apropriada
        """
        # TODO: Implementar l√≥gica de decis√£o
        pass
    
    def _generate_justification(self, summary: EvaluationSummary) -> str:
        """
        Gera justificativa textual para a decis√£o.
        
        Args:
            summary: Resumo da avalia√ß√£o
            
        Returns:
            Justificativa em linguagem natural
        """
        # TODO: Implementar gera√ß√£o de justificativa
        pass
    
    def _generate_recommendations(self, failed_criteria: List[CriterionResult]) -> List[str]:
        """
        Gera recomenda√ß√µes para crit√©rios n√£o atendidos.
        
        Args:
            failed_criteria: Lista de crit√©rios que falharam
            
        Returns:
            Lista de recomenda√ß√µes espec√≠ficas
        """
        # TODO: Implementar gera√ß√£o de recomenda√ß√µes
        pass
    
    def generate_detailed_report(self, summary: EvaluationSummary,
                               project_name: str) -> str:
        """
        Gera relat√≥rio detalhado da avalia√ß√£o.
        
        Args:
            summary: Resumo da avalia√ß√£o
            project_name: Nome do projeto avaliado
            
        Returns:
            Relat√≥rio formatado em texto
        """
        # TODO: Implementar gera√ß√£o de relat√≥rio
        pass

def main():
    """Fun√ß√£o principal para testar os tr√™s cen√°rios."""
    evaluator = SimpleCriteriaEvaluator()
    
    test_cases = [
        ("Fintech", fintech_metrics, criteria_fintech),
        ("Startup", startup_metrics, criteria_startup),
        ("Prototipo", prototype_metrics, criteria_prototype)
    ]
    
    print("=== AVALIADOR DE CRIT√âRIOS DE PARADA ===")
    print()
    
    for project_name, metrics, criteria in test_cases:
        print(f"üîç Avaliando projeto: {project_name}")
        
        # TODO: Avaliar crit√©rios e exibir resultado
        # summary = evaluator.evaluate_all_criteria(metrics, criteria)
        # report = evaluator.generate_detailed_report(summary, project_name)
        # print(report)
        print("-" * 60)

if __name__ == "__main__":
    main()
```

## Tarefas Espec√≠ficas

### Tarefa 1: Implementa√ß√£o dos Operadores
Implemente suporte robusto para todos os operadores l√≥gicos com tratamento de tipos.

### Tarefa 2: L√≥gica de Combina√ß√£o
Implemente a l√≥gica para combinar crit√©rios obrigat√≥rios, condicionais e de escape.

### Tarefa 3: Tratamento de Erros
Adicione valida√ß√£o para:
- M√©tricas ausentes
- Operadores inv√°lidos  
- Tipos incompat√≠veis
- Configura√ß√µes malformadas

### Tarefa 4: Gera√ß√£o de Relat√≥rios
Crie relat√≥rios informativos e acion√°veis que expliquem claramente as decis√µes.

## Resultados Esperados

### Projeto Fintech
- **Decis√£o:** CONTINUAR
- **Motivo:** 1 vulnerabilidade de seguran√ßa (crit√©rio obrigat√≥rio falhou)
- **Recomenda√ß√£o:** Corrigir vulnerabilidade antes de continuar

### Projeto Startup
- **Decis√£o:** PARAR
- **Motivo:** Todos os crit√©rios atendidos
- **Observa√ß√£o:** Projeto pronto para release

### Projeto Prototipo  
- **Decis√£o:** PARAR
- **Motivo:** Crit√©rio de escape ativado (demo_deadline)
- **Observa√ß√£o:** Deadline for√ßa release mesmo com cobertura baixa

## Casos de Teste

```python
# Teste 1: Crit√©rio simples com n√∫meros
assert evaluator.evaluate_single_criterion(
    "coverage", 85.5, {"target": 80.0, "operator": ">="}, 
    CriteriaType.MANDATORY
).satisfied == True

# Teste 2: Crit√©rio com booleanos
assert evaluator.evaluate_single_criterion(
    "tests_pass", True, {"target": True, "operator": "=="}, 
    CriteriaType.MANDATORY
).satisfied == True

# Teste 3: Operador incorreto
# Deve levantar ValueError

# Teste 4: M√©trica ausente  
# Deve ser tratado graciosamente
```

## Crit√©rios de Avalia√ß√£o

| Aspecto | Excelente (4) | Bom (3) | Satisfat√≥rio (2) | Insuficiente (1) |
|---------|---------------|---------|------------------|------------------|
| **L√≥gica de Avalia√ß√£o** | Todos os tipos de crit√©rios implementados corretamente | Implementa√ß√£o s√≥lida com pequenos gaps | L√≥gica b√°sica funcional | L√≥gica incompleta ou incorreta |
| **Tratamento de Tipos** | Suporte robusto para int, float, bool | Suporte adequado com valida√ß√£o | Suporte b√°sico funcional | Problemas com tipos diferentes |
| **Relat√≥rios e Mensagens** | Relat√≥rios claros e acion√°veis | Relat√≥rios informativos | Relat√≥rios b√°sicos mas √∫teis | Relat√≥rios confusos ou in√∫teis |
| **Robustez** | Tratamento excelente de casos extremos | Boa valida√ß√£o e tratamento de erros | Valida√ß√£o b√°sica adequada | Pouco ou nenhum tratamento de erros |

## Dicas de Implementa√ß√£o

üí° **Valida√ß√£o primeiro:** Implemente valida√ß√£o robusta antes da l√≥gica principal  

üí° **Estruture a decis√£o:** Use enum para decis√µes e tipos para clareza  

üí° **Mensagens contextuais:** Personalize mensagens baseado no tipo de crit√©rio  

üí° **Teste incremental:** Teste cada tipo de crit√©rio separadamente primeiro  

üí° **Logs de debug:** Adicione prints para acompanhar o fluxo de decis√£o  

## Entreg√°veis

1. **`criteria_evaluator.py`** - Implementa√ß√£o completa do avaliador
2. **`test_scenarios.py`** - Script demonstrando os tr√™s cen√°rios
3. **`evaluation_reports.txt`** - Relat√≥rios dos tr√™s projetos
4. **`reflexao.md`** - Reflex√£o sobre:
   - Desafios de automatizar decis√µes subjetivas
   - Import√¢ncia de configurabilidade vs. simplicidade
   - Li√ß√µes sobre comunica√ß√£o de decis√µes automatizadas

## Extens√µes Opcionais (B√¥nus)

üéØ **Crit√©rios com peso:** Implemente pesos diferentes para crit√©rios  
üéØ **Hist√≥rico de decis√µes:** Salve e compare decis√µes ao longo do tempo  
üéØ **Simula√ß√£o de cen√°rios:** Permita testar "e se" com m√©tricas modificadas  
üéØ **Export para JSON:** Salve configura√ß√µes e resultados estruturados  

---

**Foque na clareza da l√≥gica e utilidade dos relat√≥rios!** ‚öñÔ∏è
